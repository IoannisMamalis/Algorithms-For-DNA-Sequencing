{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c127450-4812-4946-bc8b-080bdc40d33b",
   "metadata": {},
   "source": [
    "# Module 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579e1b8-8c7b-41e7-a773-0abbf18a61fc",
   "metadata": {},
   "source": [
    "Given functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d87512-f341-4fd9-aeca-3f96fd58ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the naive exact matching algorithm\n",
    "def naive(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):  # loop over alignments\n",
    "        match = True\n",
    "        for j in range(len(p)):  # loop over characters\n",
    "            if t[i+j] != p[j]:  # compare characters\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "    return occurrences\n",
    "    \n",
    "\n",
    "# function that takes a DNA string and returns its reverse complement\n",
    "def reverseComplement(s):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    t = ''\n",
    "    for base in s:\n",
    "        t = complement[base] + t\n",
    "    return t\n",
    "\n",
    "\n",
    "# function that parses a DNA reference genome from a file in the FASTA format.\n",
    "def readGenome(filename):\n",
    "    genome = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # ignore header line with genome information\n",
    "            if not line[0] == '>':\n",
    "                genome += line.rstrip()\n",
    "    return genome\n",
    "\n",
    "\n",
    "# function that parses the read and quality strings from a FASTQ file containing sequencing reads.\n",
    "def readFastq(filename):\n",
    "    sequences = []\n",
    "    qualities = []\n",
    "    with open(filename) as fh:\n",
    "        while True:\n",
    "            fh.readline()  # skip name line\n",
    "            seq = fh.readline().rstrip()  # read base sequence\n",
    "            fh.readline()  # skip placeholder line\n",
    "            qual = fh.readline().rstrip() # base quality line\n",
    "            if len(seq) == 0:\n",
    "                break\n",
    "            sequences.append(seq)\n",
    "            qualities.append(qual)\n",
    "    return sequences, qualities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e27ef4-50e4-4176-80aa-cf690f7df588",
   "metadata": {},
   "source": [
    "First, implement a version of the naive exact matching algorithm that is strand-aware. That is, instead of looking only for occurrences of P in T, additionally look for occurrences of thereverse complement of P in T. If P is ACT, your function should find occurrences of both ACTand its reverse complement AGT in T.\n",
    "\n",
    "If P and its reverse complement are identical (e.g. AACGTT), then a given match offset should be reported only once. So if your new function is called naive_with_rc, then the old naivefunction and your new naive_with_rc function should return the same results when P equals its reverse complement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "278168ec-720f-4e47-a903-7729cab7fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_with_rc(pattern, text):\n",
    "    \"\"\"\n",
    "    Strand-aware exact matching algorithm.\n",
    "    Searches for occurrences of pattern and its reverse complement (if it's different) in text.\n",
    "    Returns sorted list.\n",
    "    \"\"\"\n",
    "    \n",
    "    occurrences = set() # Using a set to counter duplicates\n",
    "    \n",
    "    for i in range(len(text) - len(pattern) + 1):\n",
    "        match = True\n",
    "        for j in range(len(pattern)):\n",
    "            if text[i+j] != pattern[j]:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.add(i)\n",
    "\n",
    "    revcom_pattern = reverseComplement(pattern)\n",
    "\n",
    "    if revcom_pattern != pattern:\n",
    "        for i in range(len(text) - len(revcom_pattern) + 1):\n",
    "            match = True\n",
    "            for j in range(len(revcom_pattern)):\n",
    "                if text[i+j] != revcom_pattern[j]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                occurrences.add(i)\n",
    "\n",
    "    return sorted(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e939a1a-1875-4334-a22b-dd8ac82905ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1 passed.\n",
      "Example 2 passed.\n",
      "Example 3 passed.\n",
      "# occurrences in Example 3: 60\n"
     ]
    }
   ],
   "source": [
    "def test_naive_with_rc():\n",
    "    # Example 1\n",
    "    p = 'CCC'\n",
    "    ten_as = 'AAAAAAAAAA'\n",
    "    t = ten_as + 'CCC' + ten_as + 'GGG' + ten_as\n",
    "    occurrences = naive_with_rc(p, t)\n",
    "    assert occurrences == [10, 23], f\"Example 1 failed: {occurrences}\"\n",
    "    print(\"Example 1 passed.\")\n",
    "\n",
    "    # Example 2\n",
    "    p = 'CGCG'\n",
    "    t = ten_as + 'CGCG' + ten_as + 'CGCG' + ten_as\n",
    "    occurrences = naive_with_rc(p, t)\n",
    "    assert occurrences == [10, 24], f\"Example 2 failed: {occurrences}\"\n",
    "    print(\"Example 2 passed.\")\n",
    "\n",
    "    phix_genome = readGenome(r'C:\\Users\\i.mamalis\\Downloads\\phix.fa')\n",
    "    occurrences = naive_with_rc('ATTA', phix_genome)\n",
    "    leftmost = min(occurrences)\n",
    "    assert leftmost == 62, f\"Example 3 failed: leftmost occurrence is {leftmost}\"\n",
    "    print(\"Example 3 passed.\")\n",
    "    print(f\"# occurrences in Example 3: {len(occurrences)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_naive_with_rc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83918fe5-6296-446e-84f6-67d912782c07",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "How many times does AGGT or its reverse complement (ACCT) occur in the lambda virus genome? E.g. if AGGTAGGT occurs 10 times and ACCTACCT occurs 12 times, you should report 22.\n",
    "\n",
    "Question 2:\n",
    "How many times does TTAATTAA or its reverse complement occur in the lambda virus genome?  \n",
    "Hint: TTAATTAA and its reverse complement are equal, so remember not to double count.\n",
    "\n",
    "Question 3:\n",
    "What is the offset of the leftmost occurrence of ACTAAGT or its reverse complement in the Lambda virus genome? E.g. if the leftmost occurrence of ACTAAGT is at offset 40 (0-based) and the leftmost occurrence of its reverse complement ACTTAGT is at offset 29, then report 29.\n",
    "\n",
    "Question 4:\n",
    "What is the offset of the leftmost occurrence of AGTCGA or its reverse complement in the Lambda virus genome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0180ca51-0762-40ad-bca6-b078c72ca19d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Number of occurrences of AGGT or its reverse complement: 306\n",
      "Question 2: Number of occurrences of TTAA or its reverse complement: 195\n",
      "Question 3: Leftmost occurrence of ACTAAGT or its reverse complement: 26028\n",
      "Question 4: Leftmost occurrence of AGTCGA or its reverse complement: 450\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\i.mamalis\\Downloads\\lambda_virus.fa'\n",
    "    \n",
    "genome = readGenome(file_path)\n",
    "\n",
    "# Question 1\n",
    "pattern_q1 = 'AGGT'\n",
    "occurrences_q1 = naive_with_rc(pattern_q1, genome)\n",
    "print(f\"Question 1: Number of occurrences of {pattern_q1} or its reverse complement: {len(occurrences_q1)}\")\n",
    "\n",
    "# Question 2\n",
    "pattern_q2 = 'TTAA'\n",
    "occurrences_q2 = naive_with_rc(pattern_q2, genome)\n",
    "print(f\"Question 2: Number of occurrences of {pattern_q2} or its reverse complement: {len(occurrences_q2)}\")\n",
    "\n",
    "# Question 3\n",
    "pattern_q3 = 'ACTAAGT'\n",
    "occurrences_q3 = naive_with_rc(pattern_q3, genome)\n",
    "leftmost_q3 = occurrences_q3[0] if occurrences_q3 else None\n",
    "print(f\"Question 3: Leftmost occurrence of {pattern_q3} or its reverse complement: {leftmost_q3}\")\n",
    "\n",
    "# Question 4\n",
    "pattern_q4 = 'AGTCGA'\n",
    "occurrences_q4 = naive_with_rc(pattern_q4, genome)\n",
    "leftmost_q4 = occurrences_q4[0] if occurrences_q4 else None\n",
    "print(f\"Question 4: Leftmost occurrence of {pattern_q4} or its reverse complement: {leftmost_q4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b650f0-369d-4aa6-9aaa-551c970409c0",
   "metadata": {},
   "source": [
    "For Questions 5 and 6, make a new version of the naivenaive function called naive_2mm that allows up to 2 mismatches per occurrence. Unlike for the previous questions, do not consider the reverse complement here.  We're looking for approximate matches for P itself, not its reverse complement.\n",
    "\n",
    "For example, ACTTTA occurs twice in ACTTACTTGATAAAGT, once at offset 0 with 2 mismatches, and once at offset 4 with 1 mismatch. So naive_2mm('ACTTTA', 'ACTTACTTGATAAAGT') should return the list [0, 4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b90443-31f8-4805-9d41-b21270f11e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_2mm(pattern, text):\n",
    "    \"\"\"\n",
    "    Finds approximate matches of a pattern within a text, allowing up to 2 mismatches.\n",
    "    \n",
    "    Args:\n",
    "        pattern (str): The pattern to search for.\n",
    "        text (str): The text in which to search for the pattern.\n",
    "        \n",
    "    Returns:\n",
    "        list: Starting indices of each match within the specified mismatch limit.\n",
    "    \"\"\"\n",
    "    \n",
    "    match_positions = []\n",
    "    pattern_length = len(pattern)\n",
    "    text_length = len(text)\n",
    "    \n",
    "    for i in range(text_length - pattern_length + 1):\n",
    "        mismatches = 0\n",
    "  \n",
    "        for j in range(pattern_length):\n",
    "            if text[i + j] != pattern[j]:\n",
    "                mismatches += 1\n",
    "              \n",
    "                if mismatches > 2:\n",
    "                    break\n",
    "\n",
    "        if mismatches <= 2:\n",
    "            match_positions.append(i)\n",
    "    \n",
    "    return match_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519643d9-7529-4adf-b0fa-7bf4eb655b3d",
   "metadata": {},
   "source": [
    "Question 5:\n",
    "How many times does TTCAAGCCTTCAAGCC occur in the Lambda virus genome when allowing up to 2 mismatches? \n",
    "\n",
    "Question 6: What is the offset of the leftmost occurrence of AGGAGGTT in the Lambda virus genome when allowing up to 2 mismatches?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d997c92-9515-4454-923c-d22b4651b80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 5: Number of occurrences of TTCAAGCC with up to 2 mismatches: 191\n",
      "Question 6: Leftmost occurrence of AGGAGGTT with up to 2 mismatches: 49\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "pattern_q5 = 'TTCAAGCC'\n",
    "occurrences_q5 = naive_2mm(pattern_q5, genome)\n",
    "print(f\"Question 5: Number of occurrences of {pattern_q5} with up to 2 mismatches: {len(occurrences_q5)}\")\n",
    "\n",
    "# Question 6\n",
    "pattern_q6 = 'AGGAGGTT'\n",
    "occurrences_q6 = naive_2mm(pattern_q6, genome)\n",
    "leftmost_q6 = occurrences_q6[0] if occurrences_q6 else None\n",
    "print(f\"Question 6: Leftmost occurrence of {pattern_q6} with up to 2 mismatches: {leftmost_q6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd71e4f8-e8af-4cce-a592-7f858bf1c8c5",
   "metadata": {},
   "source": [
    "\n",
    "Finally, download and parse the provided FASTQ file containing real DNA sequencing reads derived from a human:\n",
    "\n",
    " https://d28rh4a8wq0iu5.cloudfront.net/ads1/data/ERR037900_1.first1000.fastq\n",
    "\n",
    "Note that the file has many reads in it and you should examine all of them together when answering this question.  The reads are taken from this study:\n",
    "\n",
    "Ajay, S. S., Parker, S. C., Abaan, H. O., Fajardo, K. V. F., & Margulies, E. H. (2011). Accurate\n",
    "\n",
    "and comprehensive sequencing of personal genomes. Genome research, 21(9), 1498-1505. \n",
    "\n",
    "This dataset has something wrong with it; one of the sequencing cycles is poor quality.\n",
    "\n",
    "Question 7:\n",
    "Report which sequencing cycle has the problem.  Remember that a sequencing cycle corresponds to a particular offset in all the reads. For example, if the leftmost read position seems to have a problem consistently across reads, report 0. If the fourth position from the left has the problem, report 3. Do whatever analysis you think is needed to identify the bad cycle. It might help to review the \"Analyzing reads by position\" video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16526423-a8c6-4737-88a9-20c7bc019ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bad_cycle(qualities):\n",
    "    \"\"\"\n",
    "    Find the sequencing cycle with the lowest average quality score, using the quality line of the genome file.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_cycles = len(qualities[0])\n",
    "    total_quality = [0] * num_cycles\n",
    "    num_reads = len(qualities)\n",
    "\n",
    "    for qual in qualities:\n",
    "        for i in range(num_cycles):\n",
    "            total_quality[i] += ord(qual[i]) - 33\n",
    "\n",
    "    avg_quality_per_cycle = [total_quality[i] / num_reads for i in range(num_cycles)]\n",
    "\n",
    "    bad_cycle = avg_quality_per_cycle.index(min(avg_quality_per_cycle))\n",
    "    \n",
    "    return bad_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6294609-89b2-4935-8124-255b99bd052d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 7: The bad sequencing cycle is at position: 66\n"
     ]
    }
   ],
   "source": [
    "# Question 7\n",
    "sequences, qualities = readFastq(r'C:\\Users\\i.mamalis\\Downloads\\ERR037900_1.first1000.fastq')\n",
    "bad_cycle = find_bad_cycle(qualities)\n",
    "print(f\"Question 7: The bad sequencing cycle is at position: {bad_cycle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490f877-4685-41cc-94fe-6b0fb7fd6818",
   "metadata": {},
   "source": [
    "# Module 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dabfbd-18c0-4761-978a-c9002f3c83bb",
   "metadata": {},
   "source": [
    "In a practical, we saw Python code implementing the Boyer-Moore algorithm. Some of the code is for preprocessing the pattern P into the tables needed to execute the bad character and good suffix rules — we did not discuss that code. But we did discuss the code that performs the algorithm given those tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c300b6-64a4-4cd4-adac-ac036f6e8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function\n",
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching. p=pattern, t=text,\n",
    "        p_bm=BoyerMoore object for p \"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    \n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        \n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "                \n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "            \n",
    "        i += shift\n",
    "        \n",
    "    return occurrences\n",
    "\n",
    "def readFasta(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        sequence = ''\n",
    "        for line in file:\n",
    "            if not line.startswith('>'):\n",
    "                sequence += line.strip()\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b2df3-7856-44ec-87ba-2b52502b8d98",
   "metadata": {},
   "source": [
    "Measuring Boyer-Moore's benefit. First, download the Python module for Boyer-Moore preprocessing:\n",
    "\n",
    "This module provides the BoyerMoore class, which encapsulates the preprocessing info used by the boyer_moore function above. Second, download the provided excerpt of human chromosome 1:\n",
    "\n",
    "Third, implement versions of the naive exact matching and Boyer-Moore algorithms that additionally count and return (a) the number of character comparisons performed and (b) the number of alignments tried. Roughly speaking, these measure how much work the two different algorithms are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd48dc8-ea37-4b14-a66e-8a43e6deb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bm_preproc import BoyerMoore\n",
    "from kmer_index import Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ded49ea-c69c-4f0a-9d60-ebf3175ef84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_with_counts(p, t):\n",
    "    \"\"\"Naive exact matching algorithm with counts of character comparisons and alignments.\"\"\"\n",
    "    \n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    \n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        \n",
    "        num_alignments += 1\n",
    "        match = True\n",
    "        \n",
    "        for j in range(len(p)):\n",
    "            num_character_comparisons += 1\n",
    "            if t[i + j] != p[j]:\n",
    "                match = False\n",
    "                break\n",
    "                \n",
    "        if match:\n",
    "            occurrences.append(i)\n",
    "            \n",
    "    return occurrences, num_alignments, num_character_comparisons\n",
    "\n",
    "\n",
    "def boyer_moore_with_counts(p, p_bm, t):\n",
    "    \"\"\"Boyer-Moore matching algorithm with counts of character comparisons and alignments.\"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    \n",
    "    while i < len(t) - len(p) + 1:\n",
    "        num_alignments += 1\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        \n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            num_character_comparisons += 1\n",
    "            \n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "                \n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs, 1)\n",
    "            \n",
    "        i += shift\n",
    "        \n",
    "    return occurrences, num_alignments, num_character_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb913e00-d47c-45cb-b69a-820cb49d2b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boyer-Moore Example 1 passed.\n",
      "Occurrences: [40]\n",
      "Number of alignments tried: 12\n",
      "Number of character comparisons: 15\n",
      "\n",
      "Boyer-Moore Example 2 passed.\n",
      "Occurrences: [0, 19]\n",
      "Number of alignments tried: 5\n",
      "Number of character comparisons: 18\n",
      "\n",
      "Naive Matching Example 1 passed.\n",
      "Occurrences: [40]\n",
      "Number of alignments tried: 41\n",
      "Number of character comparisons: 46\n",
      "\n",
      "Naive Matching Example 2 passed.\n",
      "Occurrences: [0, 19]\n",
      "Number of alignments tried: 20\n",
      "Number of character comparisons: 35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_boyer_moore_and_naive_with_counts():\n",
    "    lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "\n",
    "    # Example 1 | Boyer-Moore\n",
    "    p = 'word'\n",
    "    t = 'there would have been a time for such a word'\n",
    "    p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "    occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "    assert occurrences == [40], f\"Boyer-Moore Example 1 failed: {occurrences}\"\n",
    "    assert num_alignments == 12, f\"Boyer-Moore Example 1 failed: {num_alignments}\"\n",
    "    assert num_character_comparisons == 15, f\"Boyer-Moore Example 1 failed: {num_character_comparisons}\"\n",
    "    print(\"Boyer-Moore Example 1 passed.\")\n",
    "    print(f\"Occurrences: {occurrences}\")\n",
    "    print(f\"Number of alignments tried: {num_alignments}\")\n",
    "    print(f\"Number of character comparisons: {num_character_comparisons}\\n\")\n",
    "\n",
    "    # Example 2 | Boyer-Moore\n",
    "    p = 'needle'\n",
    "    t = 'needle need noodle needle'\n",
    "    p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "    occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "    assert occurrences == [0, 19], f\"Boyer-Moore Example 2 failed: {occurrences}\"\n",
    "    assert num_alignments == 5, f\"Boyer-Moore Example 2 failed: {num_alignments}\"\n",
    "    assert num_character_comparisons == 18, f\"Boyer-Moore Example 2 failed: {num_character_comparisons}\"\n",
    "    print(\"Boyer-Moore Example 2 passed.\")\n",
    "    print(f\"Occurrences: {occurrences}\")\n",
    "    print(f\"Number of alignments tried: {num_alignments}\")\n",
    "    print(f\"Number of character comparisons: {num_character_comparisons}\\n\")\n",
    "\n",
    "    # Example 1 | Naive Matching\n",
    "    p = 'word'\n",
    "    t = 'there would have been a time for such a word'\n",
    "    occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "    assert occurrences == [40], f\"Naive Matching Example 1 failed: {occurrences}\"\n",
    "    assert num_alignments == 41, f\"Naive Matching Example 1 failed: {num_alignments}\"\n",
    "    assert num_character_comparisons == 46, f\"Naive Matching Example 1 failed: {num_character_comparisons}\"\n",
    "    print(\"Naive Matching Example 1 passed.\")\n",
    "    print(f\"Occurrences: {occurrences}\")\n",
    "    print(f\"Number of alignments tried: {num_alignments}\")\n",
    "    print(f\"Number of character comparisons: {num_character_comparisons}\\n\")\n",
    "\n",
    "    # Example 2 | Naive Matching\n",
    "    p = 'needle'\n",
    "    t = 'needle need noodle needle'\n",
    "    occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "    assert occurrences == [0, 19], f\"Naive Matching Example 2 failed: {occurrences}\"\n",
    "    assert num_alignments == 20, f\"Naive Matching Example 2 failed: {num_alignments}\"\n",
    "    assert num_character_comparisons == 35, f\"Naive Matching Example 2 failed: {num_character_comparisons}\"\n",
    "    print(\"Naive Matching Example 2 passed.\")\n",
    "    print(f\"Occurrences: {occurrences}\")\n",
    "    print(f\"Number of alignments tried: {num_alignments}\")\n",
    "    print(f\"Number of character comparisons: {num_character_comparisons}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_boyer_moore_and_naive_with_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e639e-3f7d-4755-86ad-2a54c63b8549",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "How many alignments does the naive exact matching algorithm try when matching the string GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG (derived from human Alu sequences) to the excerpt of human chromosome 1?  (Don't consider reverse complements.)\n",
    "\n",
    "Question 2:\n",
    "How many character comparisons does the naive exact matching algorithm try when matching the string GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG (derived from human Alu sequences) to the excerpt of human chromosome 1?  (Don't consider reverse complements.)\n",
    "\n",
    "Question 3:\n",
    "How many alignments does Boyer-Moore try when matching the string GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG (derived from human Alu sequences) to the excerpt of human chromosome 1?  (Don't consider reverse complements.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45dad0f4-7255-41d9-bcca-2ee0e4df29b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern length: 47\n",
      "Question 1:\n",
      "Number of alignments tried by naive exact matching: 799954\n",
      "\n",
      "Question 2:\n",
      "Number of character comparisons by naive exact matching: 984143\n",
      "\n",
      "Question 3:\n",
      "Number of alignments tried by Boyer-Moore: 127974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = readFasta('chr1.GRCh38.excerpt.fasta')\n",
    "\n",
    "p = ('GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG')\n",
    "print(\"Pattern length:\", len(p))\n",
    "\n",
    "# Question 1\n",
    "_, num_alignments_naive, _ = naive_with_counts(p, t)\n",
    "print(\"Question 1:\")\n",
    "print(f\"Number of alignments tried by naive exact matching: {num_alignments_naive}\\n\")\n",
    "\n",
    "# Question 2\n",
    "_, _, num_character_comparisons_naive = naive_with_counts(p, t)\n",
    "print(\"Question 2:\")\n",
    "print(f\"Number of character comparisons by naive exact matching: {num_character_comparisons_naive}\\n\")\n",
    "\n",
    "# Question 3\n",
    "alphabet = 'ACGT'\n",
    "p_bm = BoyerMoore(p, alphabet)\n",
    "_, num_alignments_bm, _ = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(\"Question 3:\")\n",
    "print(f\"Number of alignments tried by Boyer-Moore: {num_alignments_bm}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1787ec-be37-4055-8831-8c4c1b05177c",
   "metadata": {},
   "source": [
    "\n",
    "Question 4:\n",
    "\n",
    "Index-assisted approximate matching. In practicals, we built a Python class called IndexIndex\n",
    "\n",
    "implementing an ordered-list version of the k-mer index.  The IndexIndex class is copied below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb92599-4515-444b-96a9-5f6ff58bd8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function\n",
    "\n",
    "import bisect\n",
    "\n",
    "class Index(object):\n",
    "    def __init__(self, t, k):\n",
    "        ''' Create index from all substrings of size 'length' '''\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "    \n",
    "    def query(self, p):\n",
    "        ''' Return index hits for first k-mer of P '''\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79061ee-c984-45cc-b3f1-5e2b7b0f0c9a",
   "metadata": {},
   "source": [
    "We also implemented the pigeonhole principle using Boyer-Moore as our exact matching algorithm.\n",
    "\n",
    "Implement the pigeonhole principle using IndexIndex to find exact matches for the partitions. Assume P always has length 24, and that we are looking for approximate matches with up to 2 mismatches (substitutions). We will use an 8-mer index.\n",
    "\n",
    "Download the Python module for building a k-mer index. \n",
    "\n",
    "https://d28rh4a8wq0iu5.cloudfront.net/ads1/code/kmer_index.py\n",
    "\n",
    "Write a function that, given a length-24 pattern P and given an IndexIndex object built on 8-mers, finds all approximate occurrences of P within T with up to 2 mismatches. Insertions and deletions are not allowed. Don't consider any reverse complements.\n",
    "\n",
    "How many times does the string GGCGCGGTGGCTCACGCCTGTAATGGCGCGGTGGCTCACGCCTGTAAT, which is derived from a human Alu sequence, occur with up to 2 substitutions in the excerpt of human chromosome 1?  (Don't consider reverse complements here.)\n",
    "\n",
    "Hint 1: Multiple index hits might direct you to the same match multiple times, but be careful not to count a match more than once.\n",
    "\n",
    "Hint 2: You can check your work by comparing the output of your new function to that of the naive_2mmnaive_2mm function implemented in the previous module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "753b5ee6-1675-4bb3-a93d-e617fdddf5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_match(P, T, max_mismatches, index):\n",
    "    \"\"\"Find approximate matches of P in T with up to max_mismatches using Index.\"\"\"\n",
    "    \n",
    "    segment_length = len(P) // (max_mismatches + 1)\n",
    "    all_matches = set()\n",
    "    index_hits = 0\n",
    "    \n",
    "    for i in range(max_mismatches + 1):\n",
    "        start = i * segment_length\n",
    "        \n",
    "        if i == max_mismatches:\n",
    "            end = len(P)\n",
    "        else:\n",
    "            end = (i + 1) * segment_length\n",
    "            \n",
    "        p_segment = P[start:end]\n",
    "  \n",
    "        p_kmer = p_segment[:index.k]\n",
    "        hits = index.query(p_kmer)\n",
    "        index_hits += len(hits)\n",
    "      \n",
    "        for hit in hits:\n",
    "            s = hit - start  \n",
    "            if s < 0 or s + len(P) > len(T):\n",
    "                continue \n",
    "            mismatches = 0\n",
    "            for j in range(len(P)):\n",
    "                if T[s + j] != P[j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > max_mismatches:\n",
    "                        break  \n",
    "            if mismatches <= max_mismatches:\n",
    "                all_matches.add(s)\n",
    "    return list(all_matches), index_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51675121-0035-42c4-8281-98cac4ae92e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 4:\n",
      "Number of occurrences with up to 2 mismatches: 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "p_approx = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "k = 8\n",
    "index = Index(t, k)\n",
    "occurrences_approx, _ = approximate_match(p_approx, t, 2, index)\n",
    "print(\"Question 4:\")\n",
    "print(f\"Number of occurrences with up to 2 mismatches: {len(occurrences_approx)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b67f47-d82a-432a-810b-4ac02194be09",
   "metadata": {},
   "source": [
    "Question 5: Using the instructions given in Question 4, how many total index hits are there when searching for occurrences of GGCGCGGTGGCTCACGCCTGTAATGGCGCGGTGGCTCACGCCTGTAAT with up to 2 substitutions in the excerpt of human chromosome 1?\n",
    "\n",
    "  (Don't consider reverse complements.)\n",
    "\n",
    "Hint: You should be able to use the boyer_mooreboyer_moore function (or the slower naivenaive function) to double-check your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b4a94f-294e-418d-9afb-c9d3d0847665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 5:\n",
      "Total number of index hits using Index: 90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "_, total_index_hits = approximate_match(p_approx, t, 2, index)\n",
    "print(\"Question 5:\")\n",
    "print(f\"Total number of index hits using Index: {total_index_hits}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31c5ea-3321-4bcd-baf5-ee96eb28b4ea",
   "metadata": {},
   "source": [
    "Question 6\n",
    "\n",
    "Let's examine whether there is a benefit to using an index built using subsequences of T rather than substrings, as we discussed in the \"Variations on k-mer indexes\" video.  We'll consider subsequences involving every N characters.  For example, if we split ATATAT into two substring partitions, we would get partitions ATA (the first half) and TAT (second half).  But if we split ATATAT into two  subsequences  by taking every other character, we would get AAA (first, third and fifth characters) and TTT (second, fourth and sixth).\n",
    "\n",
    "Another way to visualize this is using numbers to show how each character of P is allocated to a partition.  Splitting a length-6 pattern into two substrings could be represented as 111222, and splitting into two subsequences of every other character could be represented as 121212\n",
    "\n",
    "The following class SubseqIndexSubseqIndex is a more general implementation of IndexIndex that additionally handles subsequences. It only considers subsequences that take every Nth character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aa9eb1a-3ddd-4f85-bb66-085e13ee37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function\n",
    "   \n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b046d9-82f1-4208-b46f-f2a5e63b43b6",
   "metadata": {},
   "source": [
    "Write a function that, given a length-24 pattern P and given a SubseqIndexSubseqIndex object built with k = 8 and ival = 3, finds all approximate occurrences of P within T with up to 2 mismatches.\n",
    "\n",
    "When using this function, how many total index hits are there when searching for GGCGCGGTGGCTCACGCCTGTAAT with up to 2 substitutions in the excerpt of human chromosome 1?  (Again, don't consider reverse complements.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c84c59cf-5ca5-4258-99aa-aeb209af4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_subseq(p, t, subseq_ind):\n",
    "    \"\"\"Find all approximate occurrences of p in t with up to 2 mismatches,\n",
    "    using the provided subsequence index.\"\"\"\n",
    "    \n",
    "    occurrences = set()\n",
    "    num_index_hits = 0\n",
    "    \n",
    "    for offset in range(3):\n",
    "        subseq = p[offset : offset + subseq_ind.span : subseq_ind.ival]\n",
    "        i = bisect.bisect_left(subseq_ind.index, (subseq, -1))\n",
    "        \n",
    "        hits = []\n",
    "        \n",
    "        while i < len(subseq_ind.index):\n",
    "            if subseq_ind.index[i][0] != subseq:\n",
    "                break\n",
    "                \n",
    "            hits.append(subseq_ind.index[i][1])\n",
    "            i += 1\n",
    "            \n",
    "        num_index_hits += len(hits)\n",
    "        \n",
    "        for hit in hits:\n",
    "            pos = hit - offset\n",
    "            \n",
    "            if pos < 0 or pos + len(p) > len(t):\n",
    "                continue \n",
    "            mismatches = 0\n",
    "            \n",
    "            for i in range(len(p)):\n",
    "                if t[pos + i] != p[i]:\n",
    "                    mismatches += 1\n",
    "                    \n",
    "                    if mismatches > 2:\n",
    "                        break  \n",
    "                        \n",
    "            if mismatches <= 2:\n",
    "                occurrences.add(pos)\n",
    "                \n",
    "    return sorted(occurrences), num_index_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f843cfd3-d4b4-4395-9d85-571a8282741b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 6:\n",
      "Total number of index hits using SubseqIndex: 79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 6\n",
    "k_subseq = 8\n",
    "ival = 3\n",
    "subseq_ind = SubseqIndex(t, k_subseq, ival)\n",
    "occurrences, num_index_hits = query_subseq(p_approx, t, subseq_ind)\n",
    "print(\"Question 6:\")\n",
    "print(f\"Total number of index hits using SubseqIndex: {num_index_hits}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98326c5-40c0-4f26-9057-fb3ccb88fc9f",
   "metadata": {},
   "source": [
    "# Module 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe8b7bf-7c78-43d8-b732-5b4806e5c183",
   "metadata": {},
   "source": [
    "We saw how to adapt dynamic programming to find approximate occurrences of a pattern in a text. Recall that:\n",
    "\n",
    "    Rows of the dynamic programming matrix are labeled with bases from P and columns with bases from T\n",
    "\n",
    "    Elements in the first row are set to 0\n",
    "\n",
    "    Elements in the first column are set to 0, 1, 2, ..., as for edit distance\n",
    "\n",
    "    Other elements are set in the same way as elements of a standard edit distance matrix\n",
    "\n",
    "    The minimal value in the bottom row is the edit distance of the closest match between P and T\n",
    "\n",
    "First, download the provided excerpt of human chromosome 1\n",
    "\n",
    "Second, parse it using the readGenome function we wrote before.\n",
    "\n",
    "Third, adapt the editDistance function we saw in practical (copied below) to answer questions 1 and 2 below. Your function should take arguments p (pattern), t (text) and should return the edit distance of the match between P and T with the fewest edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b075be5-259e-4ae0-8f12-6058fe8f20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function\n",
    "def editDistance(x, y):\n",
    "    # Create distance matrix\n",
    "    D = []\n",
    "    for i in range(len(x)+1):\n",
    "        D.append([0]*(len(y)+1))\n",
    "    # Initialize first row and column of matrix\n",
    "    for i in range(len(x)+1):\n",
    "        D[i][0] = i\n",
    "    for i in range(len(y)+1):\n",
    "        D[0][i] = i\n",
    "    # Fill in the rest of the matrix\n",
    "    for i in range(1, len(x)+1):\n",
    "        for j in range(1, len(y)+1):\n",
    "            distHor = D[i][j-1] + 1\n",
    "            distVer = D[i-1][j] + 1\n",
    "            if x[i-1] == y[j-1]:\n",
    "                distDiag = D[i-1][j-1]\n",
    "            else:\n",
    "                distDiag = D[i-1][j-1] + 1\n",
    "            D[i][j] = min(distHor, distVer, distDiag)\n",
    "    # Edit distance is the value in the bottom right corner of the matrix\n",
    "    return D[-1][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39c2243a-f48a-4ecf-a4b9-af30fd608e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximateMatch(p, t):\n",
    "    \"\"\"Finds the minimal edit distance between pattern 'p' and any substring of text 't'.\"\"\"\n",
    "    \n",
    "    m = len(p)\n",
    "    n = len(t)\n",
    "    \n",
    "    previous_row = [0] * (n + 1)\n",
    "    \n",
    "    for i in range(1, m + 1):\n",
    "        current_row = [i] + [0] * n\n",
    "        \n",
    "        for j in range(1, n + 1):\n",
    "            \n",
    "            if p[i - 1] == t[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "                \n",
    "            current_row[j] = min(\n",
    "                previous_row[j] + 1,        \n",
    "                current_row[j - 1] + 1,    \n",
    "                previous_row[j - 1] + cost \n",
    "            )\n",
    "            \n",
    "        previous_row = current_row\n",
    "\n",
    "    min_edit_distance = min(previous_row)\n",
    "    \n",
    "    return min_edit_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d216b246-549a-412b-ad96-b258fe61600f",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "What is the edit distance of the best match between pattern GCTGATCGATCGTACGGCTGATCGATCGTACG and the excerpt of human chromosome 1?  (Don't consider reverse complements.)\n",
    "\n",
    "Question 2:\n",
    "What is the edit distance of the best match between pattern GATTTACCAGATTGAGGATTTACCAGATTGAG and the excerpt of human chromosome 1?  (Don't consider reverse complements.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d93a9a1b-8421-4f9b-91b3-ae42cd6bd619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 Answer:\n",
      "3\n",
      "\n",
      "Question 2 Answer:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "genome = readGenome('chr1.GRCh38.excerpt.fasta')\n",
    "pattern1 = 'GCTGATCGATCGTACG'\n",
    "distance1 = approximateMatch(pattern1, genome)\n",
    "print(\"Question 1 Answer:\")\n",
    "print(distance1)\n",
    "\n",
    "# Question 2\n",
    "pattern2 = 'GATTTACCAGATTGAG'\n",
    "distance2 = approximateMatch(pattern2, genome)\n",
    "print(\"\\nQuestion 2 Answer:\")\n",
    "print(distance2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb641fd-712e-4961-8292-e8aed92f8328",
   "metadata": {},
   "source": [
    "\n",
    "Question 3\n",
    "\n",
    "In a practical, we saw a function for finding the longest exact overlap (suffix/prefix match) between two strings. The function is copied below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a1b266c-d1a5-4419-8d8d-8485963a83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(a, b, min_length=3):\n",
    "    \"\"\" Return length of longest suffix of 'a' matching\n",
    "        a prefix of 'b' that is at least 'min_length'\n",
    "        characters long.  If no such overlap exists,\n",
    "        return 0. \"\"\"\n",
    "    start = 0  # start all the way at the left\n",
    "    while True:\n",
    "        start = a.find(b[:min_length], start)  # look for b's prefix in a\n",
    "        if start == -1:  # no more occurrences to right\n",
    "            return 0\n",
    "        # found occurrence; check for full suffix/prefix match\n",
    "        if b.startswith(a[start:]):\n",
    "            return len(a)-start\n",
    "        start += 1  # move just past previous match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dff479-a6d9-4ee5-bf06-c3c77e08253e",
   "metadata": {},
   "source": [
    "Say we are concerned only with overlaps that (a) are exact matches (no differences allowed), and (b) are at least kk bases long. To make an overlap graph, we could call overlap(a, b, min_length=k)overlap(a, b, min_length=k) on every possible pair of reads from the dataset.  Unfortunately, that will be very slow!\n",
    "\n",
    "Consider this: Say we are using k=6, and we have a read aa whose length-6 suffix is GTCCTA.  Say GTCCTA does not occur in any other read in the dataset.  In other words, the 6-mer GTCCTA occurs at the end of read aa and nowhere else.  It follows that aa's suffix cannot possibly overlap the prefix of any other read by 6 or more characters.\n",
    "\n",
    "Put another way, if we want to find the overlaps involving a suffix of read aa and a prefix of some other read, we can ignore any reads that don't contain the length-k suffix of aa.  This is good news because it can save us a lot of work!\n",
    "\n",
    "Here is a suggestion for how to implement this idea.  You don't have to do it this way, but this might help you.  Let every k-mer in the dataset have an associated Python setset object, which starts out empty.  We use a Python dictionary to associate each k-mer with its corresponding setset. (1) For every k-mer in a read, we add the read to the setset object corresponding to that k-mer.  If our read is GATTAGATTA and k=3, we would add GATTAGATTA to the setset objects for GATGAT, ATTATT and TTATTA.  We do this for every read so that, at the end, each setset contains all reads containing the corresponding k-mer.  (2) Now, for each read aa, we find all overlaps involving a suffix of aa.  To do this, we take aa's length-k suffix, find all reads containing that k-mer (obtained from the corresponding setset) and call overlap(a, b, min_length=k)overlap(a, b, min_length=k) for each.\n",
    "\n",
    "The most important point is that we do not call overlap(a, b, min_length=k)overlap(a, b, min_length=k) if bb does not contain the length-k suffix of a.\n",
    "\n",
    "Download and parse the read sequences from the provided Phi-X FASTQ file. We'll just use their base sequences, so you can ignore read names and base qualities.  Also, no two reads in the FASTQ have the same sequence of bases.  This makes things simpler.\n",
    "\n",
    "\n",
    "Next, find all pairs of reads with an exact suffix/prefix match of length at least 30. Don't overlap a read with itself; if a read has a suffix/prefix match to itself, ignore that match.  Ignore reverse complements.\n",
    "\n",
    "    Hint 1: Your function should not take much more than 15 seconds to run on this 10,000-read dataset, and maybe much less than that.  (Our solution takes about 3 seconds.) If your function is much slower, there is a problem somewhere.\n",
    "\n",
    "    Hint 2: Remember not to overlap a read with itself. If you do, your answers will be too high.\n",
    "\n",
    "    Hint 3: You can test your implementation by making up small examples, then checking that (a) your implementation runs quickly, and (b) you get the same answer as if you had simply called overlap(a, b, min_length=k)overlap(a, b, min_length=k) on every pair of reads.  We also have provided a couple examples you can check against\n",
    "\n",
    "    .\n",
    "\n",
    "Picture the overlap graph corresponding to the overlaps just calculated.  How many edges are in the graph?  In other words, how many distinct pairs of reads overlap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e8cc2-e0a2-4cc7-9134-b389c33d11d3",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "Picture the overlap graph corresponding to the overlaps computed for the previous question. How many nodes in this graph have at least one outgoing edge?  (In other words, how many reads have a suffix involved in an overlap?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43fe6222-15a0-46f8-8c3a-c3239707062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 3 Answer:\n",
      "904746\n",
      "\n",
      "Question 4 Answer:\n",
      "7161\n"
     ]
    }
   ],
   "source": [
    "# Question 3 and 4\n",
    "sequences, qualities = readFastq('ERR266411_1.for_asm.fastq')\n",
    "\n",
    "k = 30\n",
    "kmer_dict = {}\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    for j in range(len(seq) - k + 1):\n",
    "        kmer = seq[j:j+k]\n",
    "        \n",
    "        if kmer not in kmer_dict:\n",
    "            kmer_dict[kmer] = set()\n",
    "            \n",
    "        kmer_dict[kmer].add(i)\n",
    "        \n",
    "overlaps = {}\n",
    "nodes_with_outgoing = set()\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    suffix = seq[-k:]\n",
    "\n",
    "    if suffix in kmer_dict:\n",
    "        for j in kmer_dict[suffix]:\n",
    "            if i != j:\n",
    "                olen = overlap(seq, sequences[j], min_length=k)\n",
    "                if olen > 0:\n",
    "                    overlaps[(i, j)] = olen\n",
    "                    nodes_with_outgoing.add(i)\n",
    "                    \n",
    "num_overlaps = len(overlaps)\n",
    "print(\"\\nQuestion 3 Answer:\")\n",
    "print(num_overlaps)\n",
    "print(\"\\nQuestion 4 Answer:\")\n",
    "print(len(nodes_with_outgoing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a35f2-17d1-4597-be41-4a8b17aa93f5",
   "metadata": {},
   "source": [
    "# Module 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c970bf0a-856c-410c-951c-aeee056cd06c",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "In a practical, we saw the scs function (copied below along with overlapoverlap) for finding the shortest common superstring of a set of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d5985b2-9e79-4446-a8de-a2a87eba4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given functions\n",
    "def overlap(a, b, min_length=3):\n",
    "    \"\"\" Return length of longest suffix of 'a' matching\n",
    "        a prefix of 'b' that is at least 'min_length'\n",
    "        characters long.  If no such overlap exists,\n",
    "        return 0. \"\"\"\n",
    "    start = 0  # start all the way at the left\n",
    "    while True:\n",
    "        start = a.find(b[:min_length], start)  # look for b's suffx in a\n",
    "        if start == -1:  # no more occurrences to right\n",
    "            return 0\n",
    "        # found occurrence; check for full suffix/prefix match\n",
    "        if b.startswith(a[start:]):\n",
    "            return len(a)-start\n",
    "        start += 1  # move just past previous match\n",
    "\n",
    "import itertools\n",
    "\n",
    "def scs(ss):\n",
    "    \"\"\" Returns shortest common superstring of given\n",
    "        strings, which must be the same length \"\"\"\n",
    "    shortest_sup = None\n",
    "    for ssperm in itertools.permutations(ss):\n",
    "        sup = ssperm[0]  # superstring starts as first string\n",
    "        for i in range(len(ss)-1):\n",
    "            # overlap adjacent strings A and B in the permutation\n",
    "            olen = overlap(ssperm[i], ssperm[i+1], min_length=1)\n",
    "            # add non-overlapping portion of B to superstring\n",
    "            sup += ssperm[i+1][olen:]\n",
    "        if shortest_sup is None or len(sup) < len(shortest_sup):\n",
    "            shortest_sup = sup  # found shorter superstring\n",
    "    return shortest_sup  # return shortest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74f787-0855-45e8-ad1b-2e8b5a31a58d",
   "metadata": {},
   "source": [
    "\n",
    "It's possible for there to be multiple different shortest common superstrings for the same set of input strings. Consider the input strings ABC, BCA, CAB. One shortest common superstring is ABCAB but another is BCABC and another is CABCA.\n",
    "\n",
    "What is the length of the shortest common superstring of the following strings?\n",
    "\n",
    "CCT, CTT, TGC, TGG, GAT, ATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4b5b4ce-53b1-4f11-952a-6c7c561a3d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest common superstring: CCTTGGATTGC\n",
      "Length: 11\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "strings = ['CCT', 'CTT', 'TGC', 'TGG', 'GAT', 'ATT']\n",
    "scs_result = scs(strings)\n",
    "# Output the result and its length\n",
    "print(\"Shortest common superstring:\", scs_result)\n",
    "print(\"Length:\", len(scs_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b816a7-49be-4045-a943-16cc9cff4fc4",
   "metadata": {},
   "source": [
    "\n",
    "Question 2:\n",
    "How many different shortest common superstrings are there for the input strings given in the previous question?\n",
    "\n",
    "Hint: You can modify the scs function to keep track of this. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "793b510d-0c68-463c-ae9e-5018096e3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scs_all(ss):\n",
    "    \n",
    "    \"\"\"Returns a set of all shortest common superstrings of given strings.\"\"\"\n",
    "    \n",
    "    shortest_sup_len = None\n",
    "    shortest_sups = set()\n",
    "    \n",
    "    for ssperm in itertools.permutations(ss):\n",
    "        sup = ssperm[0]  \n",
    "        \n",
    "        for i in range(len(ssperm) - 1):\n",
    "            olen = overlap(ssperm[i], ssperm[i + 1], min_length=1)\n",
    "            sup += ssperm[i + 1][olen:]\n",
    "            \n",
    "        if (shortest_sup_len is None) or (len(sup) < shortest_sup_len):\n",
    "            shortest_sup_len = len(sup)\n",
    "            shortest_sups = {sup}\n",
    "            \n",
    "        elif len(sup) == shortest_sup_len:\n",
    "            shortest_sups.add(sup)\n",
    "            \n",
    "    return shortest_sups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f9e3e03-d9e4-42a8-807b-0fab1fe999a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2 Answer:\n",
      "Length of the shortest common superstring: 11\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "shortest_superstrings = scs_all(strings)\n",
    "print(\"\\nQuestion 2 Answer:\")\n",
    "print(\"Length of the shortest common superstring:\", len(next(iter(shortest_superstrings))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d0b08-66d6-4323-b2e7-bf4bb9519068",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "Download this FASTQ file containing synthetic sequencing reads from a mystery virus:\n",
    "\n",
    "All the reads are the same length (100 bases) and are exact copies of substrings from the forward strand of the virus genome.  You don't have to worry about sequencing errors, ploidy, or reads coming from the reverse strand.\n",
    "\n",
    "Assemble these reads using one of the approaches discussed, such as greedy shortest common superstring.  Since there are many reads, you might consider ways to make the algorithm faster, such as the one discussed in the programming assignment in the previous module.\n",
    "\n",
    "How many As are there in the full, assembled genome?\n",
    "\n",
    "Hint: the virus genome you are assembling is exactly 15,894 bases long\n",
    "\n",
    "Question 4:\n",
    "How many Ts are there in the full, assembled genome from the previous question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2779f92b-bac9-47eb-b20d-9d78dd9234c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kmer_dict(reads, k):\n",
    "    \n",
    "    \"\"\"Builds a dictionary mapping each k-mer to a set of reads containing that k-mer.\"\"\"\n",
    "    \n",
    "    kmer_dict = {}\n",
    "    \n",
    "    for read in reads:\n",
    "        for i in range(len(read) - k + 1):\n",
    "            kmer = read[i:i+k]\n",
    "            \n",
    "            if kmer in kmer_dict:\n",
    "                kmer_dict[kmer].add(read)\n",
    "            else:\n",
    "                kmer_dict[kmer] = set([read])\n",
    "                \n",
    "    return kmer_dict\n",
    "\n",
    "def pick_maximal_overlap(reads, kmer_dict, k):\n",
    "    \n",
    "    \"\"\"Finds the pair of reads with the maximal suffix/prefix overlap.\"\"\"\n",
    "    \n",
    "    read_a, read_b = None, None\n",
    "    best_olen = 0\n",
    "    \n",
    "    for a in reads:\n",
    "        suffix = a[-k:]\n",
    "        if suffix in kmer_dict:\n",
    "            candidates = kmer_dict[suffix]\n",
    "            \n",
    "            for b in candidates:\n",
    "                if a != b:\n",
    "                    olen = overlap(a, b, min_length=k)\n",
    "                    if olen > best_olen:\n",
    "                        best_olen = olen\n",
    "                        read_a, read_b = a, b\n",
    "                        \n",
    "    return read_a, read_b, best_olen\n",
    "\n",
    "def greedy_scs(reads, k):\n",
    "    \n",
    "    \"\"\"Assemble the genome using a greedy shortest common superstring approach with k-mer optimization.\"\"\"\n",
    "    \n",
    "    reads = reads.copy() \n",
    "    \n",
    "    while True:\n",
    "        kmer_dict = build_kmer_dict(reads, k)\n",
    "        read_a, read_b, olen = pick_maximal_overlap(reads, kmer_dict, k)\n",
    "        \n",
    "        if olen == 0:\n",
    "            break\n",
    "            \n",
    "        reads.remove(read_a)\n",
    "        reads.remove(read_b)\n",
    "        merged_read = read_a + read_b[olen:]\n",
    "        reads.append(merged_read)\n",
    "\n",
    "    assembled_genome = ''.join(reads)\n",
    "    \n",
    "    return assembled_genome\n",
    "\n",
    "def count_bases(sequence):\n",
    "    \n",
    "    \"\"\"Count the number of each base in the sequence.\"\"\"\n",
    "    \n",
    "    counts = {}\n",
    "    \n",
    "    for base in sequence:\n",
    "        if base in counts:\n",
    "            counts[base] += 1\n",
    "        else:\n",
    "            counts[base] = 1\n",
    "            \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cc1e898-c527-4f53-9a04-4b21cd17658d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reads: 1881\n",
      "Length of assembled genome: 15894\n",
      "Number of As: 4633\n",
      "Number of Ts: 3723\n"
     ]
    }
   ],
   "source": [
    "filename = 'ads1_week4_reads.fq'\n",
    "\n",
    "sequences, qualities = readFastq(filename)\n",
    "sequences, qualities = readFastq(filename)\n",
    "reads = sequences\n",
    "print(\"Total reads:\", len(reads))\n",
    "\n",
    "assembled_genome = greedy_scs(reads, k=30)\n",
    "print(\"Length of assembled genome:\", len(assembled_genome))\n",
    "\n",
    "base_counts = count_bases(assembled_genome)\n",
    "num_As = base_counts.get('A', 0)\n",
    "num_Ts = base_counts.get('T', 0)\n",
    "print(\"Number of As:\", num_As)\n",
    "print(\"Number of Ts:\", num_Ts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
